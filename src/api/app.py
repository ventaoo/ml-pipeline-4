import configparser
import os
import sys
import json
import joblib
from datetime import datetime
import numpy as np
from fastapi import FastAPI
from pydantic import BaseModel
from gensim.models import Word2Vec
from dotenv import load_dotenv
from kafka import KafkaProducer
from kafka import KafkaConsumer
from threading import Thread
from contextlib import asynccontextmanager

sys.path.insert(1, os.path.join(os.getcwd(), "src"))

from db import store_prediction_results

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„æ•°æ®åº“è¿æ¥ä¿¡æ¯
load_dotenv()

# è·å–æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼ˆä»ç¯å¢ƒå˜é‡ä¸­è¯»å–ï¼‰
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
DB_NAME = os.getenv("DB_NAME")

# å®šä¹‰ Consumer åå°ä»»åŠ¡
def consume_messages():
    consumer = KafkaConsumer(
        "model-results",
        bootstrap_servers=os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092"),
        auto_offset_reset="earliest",
        value_deserializer=lambda x: json.loads(x.decode("utf-8"))
    )
    for message in consumer:
        print(f"Consumer æ”¶åˆ°æ¶ˆæ¯: {message.value}")
        # åœ¨æ­¤å¤„æ·»åŠ ä¸šåŠ¡é€»è¾‘ï¼ˆå¦‚ä¿å­˜åˆ°æ•°æ®åº“ï¼‰

# å®šä¹‰æ•°æ®è¾“å…¥æ ¼å¼
class InputData(BaseModel):
    text: str

# API ç±»
class api_():
    def __init__(self):
        # è¯»å–é…ç½®æ–‡ä»¶
        self.config = configparser.ConfigParser()
        self.config.read("config.ini")

        # åŠ è½½æ¨¡å‹
        self.model = joblib.load(self.config['LOG_REG']['path'])
        self.word2vec_model = Word2Vec.load(self.config['WORD2VEC']['model_path'])

    def text_to_vector(self, model, text):
        """ å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯å‘é‡çš„å¹³å‡å€¼ """
        words = text.split()
        vectors = [model.wv[word] for word in words if word in model.wv]
        return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)

    def predict(self, input_text):
        """ æ‰§è¡Œé¢„æµ‹ """
        input_data = np.array([self.text_to_vector(self.word2vec_model, input_text)])
        prediction = self.model.predict(input_data)
        return int(prediction)  # ç¡®ä¿è¿”å›æ•´æ•°

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸš€ æœåŠ¡å™¨å¯åŠ¨!")
     # ä»ç¯å¢ƒå˜é‡è¯»å– Kafka é…ç½®ï¼ˆç¤ºä¾‹å€¼ï¼škafka:9092ï¼‰
    app.kafka_producer = KafkaProducer(
        bootstrap_servers=os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092"),
        value_serializer=lambda v: json.dumps(v).encode("utf-8")
    )
    print('Kafka producer å¯åŠ¨!')

    # å¯åŠ¨ Consumer çº¿ç¨‹
    Thread(target=consume_messages, daemon=True).start()
    print('Kafka consumer å¯åŠ¨!')

    yield
    
    app.kafka_producer.close()
    print("ğŸ›‘ æœåŠ¡å™¨å…³é—­!")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(lifespan=lifespan)

# é¢„æµ‹ API å®ä¾‹
api_interface = api_()

# é¢„æµ‹æ¥å£
@app.get("/predict/{data}")
def predict(data: str):
    prediction = api_interface.predict(data)
    
    # å­˜å…¥æ•°æ®åº“æ—¶å­˜å‚¨ (è¾“å…¥æ–‡æœ¬, é¢„æµ‹ç»“æœ)
    store_prediction_results([(data, prediction)], "predictions")  

    # å‘é€æ¶ˆæ¯åˆ° Kafka
    message = {
        "input": data,
        "prediction": prediction,
        "timestamp": datetime.now().isoformat()
    }
    app.kafka_producer.send("model-results", value=message)
    
    return {"input": data, "prediction": prediction}
